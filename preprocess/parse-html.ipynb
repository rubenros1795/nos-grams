{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from glob import glob as gb \n",
    "from bs4 import BeautifulSoup as bs\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import collections\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import json,sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_files = gb('html/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_soup(fn):\n",
    "    with open(fn,'r') as f:\n",
    "        c = f.read()\n",
    "    return bs(c)\n",
    "\n",
    "def parse_metadata(soup):\n",
    "\n",
    "    metadata = {}\n",
    "    elements = [x.text for x in s.find_all('span') if '•' in x.text and len(x.text) != 1]\n",
    "    elements = [x.replace('• ','') for x in elements]\n",
    "    elements = [x.replace('\\n','') for x in elements]\n",
    "    category = [x for x in elements if x.isdigit() == False][0].split(' •')\n",
    "    category = [x[:-1] if x[-1] == ' ' else x for x in category]\n",
    "    \n",
    "    metadata['categories'] = category\n",
    "\n",
    "    dates = [x for x in elements if any(i.isdigit() for i in x) == True]\n",
    "\n",
    "    if len(dates) == 2:\n",
    "        date_edit = [x for x in dates if 'gepast' in x][0]\n",
    "        date_edit = date_edit.replace('Aangepast','').replace('• ','').replace('\\t','')\n",
    "        date_or = [x for x in dates if 'gepast' not in x][0]\n",
    "\n",
    "        metadata['date'] = date_or\n",
    "        metadata['date_edited'] = date_edit[11:]\n",
    "    else:\n",
    "        metadata['date'] = dates[0]\n",
    "        metadata['date_edited'] = None\n",
    "\n",
    "    metadata['title'] = soup.find('h1').text.replace('\\n','').lstrip()\n",
    "    return metadata\n",
    "\n",
    "def find_pars(soup):\n",
    "    return [x.text.replace('\\xa0',' ') for x in s.find_all('p') if 'text' in x.attrs['class'][0] or 'heading' in x.attrs['class'][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 225100/225100 [58:30<00:00, 64.12it/s]\n"
     ]
    }
   ],
   "source": [
    "d = {}\n",
    "for i in tqdm(list_files):\n",
    "    s = parse_soup(i)\n",
    "    try:\n",
    "        metadata = parse_metadata(s)\n",
    "        # paragraphs = find_pars(s)\n",
    "        d[i] = metadata\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('metadata.json','w') as f:\n",
    "    json.dump(d,f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.6 64-bit",
   "name": "python386jvsc74a57bd031f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "language_info": {
   "name": "python",
   "version": ""
  },
  "metadata": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}